{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOr_PecHZOms",
        "outputId": "7676b948-444b-48fe-a15c-bbe356e12751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  @AppleSupport causing the reply to be disregar...   \n",
            "1  @105835 Your business means a lot to us. Pleas...   \n",
            "2  @76328 I really hope you all change but I'm su...   \n",
            "3  @105836 LiveChat is online at the moment - htt...   \n",
            "4  @VirginTrains see attached error message. I've...   \n",
            "\n",
            "                                          text_lower  \n",
            "0  @applesupport causing the reply to be disregar...  \n",
            "1  @105835 your business means a lot to us. pleas...  \n",
            "2  @76328 i really hope you all change but i'm su...  \n",
            "3  @105836 livechat is online at the moment - htt...  \n",
            "4  @virgintrains see attached error message. i've...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('/content/sample.csv')\n",
        "\n",
        "# Convert text column to lowercase\n",
        "df['text_lower'] = df['text'].str.lower()\n",
        "\n",
        "print(df[['text', 'text_lower']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df['no_punctuation'] = df['text_lower'].apply(remove_punctuation)\n",
        "\n",
        "print(df[['text_lower', 'no_punctuation']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDXMohsna45K",
        "outputId": "10872bdf-3610-4dfe-988f-3faa8d49df3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          text_lower  \\\n",
            "0  @applesupport causing the reply to be disregar...   \n",
            "1  @105835 your business means a lot to us. pleas...   \n",
            "2  @76328 i really hope you all change but i'm su...   \n",
            "3  @105836 livechat is online at the moment - htt...   \n",
            "4  @virgintrains see attached error message. i've...   \n",
            "\n",
            "                                      no_punctuation  \n",
            "0  applesupport causing the reply to be disregard...  \n",
            "1  105835 your business means a lot to us please ...  \n",
            "2  76328 i really hope you all change but im sure...  \n",
            "3  105836 livechat is online at the moment  https...  \n",
            "4  virgintrains see attached error message ive tr...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered = [word for word in words if word.lower() not in stop_words]\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "df['no_stopwords'] = df['no_punctuation'].apply(remove_stopwords)\n",
        "\n",
        "print(df[['no_punctuation', 'no_stopwords']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eEZXs-5bIqy",
        "outputId": "91c5df07-0030-4ecf-8386-4908120f8c74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      no_punctuation  \\\n",
            "0  applesupport causing the reply to be disregard...   \n",
            "1  105835 your business means a lot to us please ...   \n",
            "2  76328 i really hope you all change but im sure...   \n",
            "3  105836 livechat is online at the moment  https...   \n",
            "4  virgintrains see attached error message ive tr...   \n",
            "\n",
            "                                        no_stopwords  \n",
            "0  applesupport causing reply disregarded tapped ...  \n",
            "1  105835 business means lot us please dm name zi...  \n",
            "2         76328 really hope change im sure wont dont  \n",
            "3  105836 livechat online moment httpstcosy94vtu8...  \n",
            "4  virgintrains see attached error message ive tr...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    stemmed = [ps.stem(word) for word in words]\n",
        "    return \" \".join(stemmed)\n",
        "\n",
        "sample_sentence = \"running runs easily studies studying\"\n",
        "print(\"Original:\", sample_sentence)\n",
        "print(\"Stemmed:\", stem_text(sample_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp5YovARb7Dy",
        "outputId": "c716332a-938b-4649-de61-c1b9d6e2c8b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: running runs easily studies studying\n",
            "Stemmed: run run easili studi studi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def spacy_lemmatize(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "print(\"SpaCy Lemmatized:\", spacy_lemmatize(sample_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhdd1rbicO7p",
        "outputId": "ea888822-d729-4bba-daaf-d4ab6b26507a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy Lemmatized: run run easily study study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "\n",
        "df['no_urls'] = df['text'].apply(remove_urls)\n",
        "\n",
        "print(df[['text', 'no_urls']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN3YjCuicYIM",
        "outputId": "50495c65-8ec0-4547-f7a2-5203c15b4895"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  @AppleSupport causing the reply to be disregar...   \n",
            "1  @105835 Your business means a lot to us. Pleas...   \n",
            "2  @76328 I really hope you all change but I'm su...   \n",
            "3  @105836 LiveChat is online at the moment - htt...   \n",
            "4  @VirginTrains see attached error message. I've...   \n",
            "\n",
            "                                             no_urls  \n",
            "0  @AppleSupport causing the reply to be disregar...  \n",
            "1  @105835 Your business means a lot to us. Pleas...  \n",
            "2  @76328 I really hope you all change but I'm su...  \n",
            "3  @105836 LiveChat is online at the moment -  or...  \n",
            "4  @VirginTrains see attached error message. I've...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(text):\n",
        "    return re.sub(r'<.*?>', '', text)\n",
        "\n",
        "df['no_html'] = df['text'].apply(remove_html_tags)\n",
        "\n",
        "print(df[['text', 'no_html']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvZwXgtPch3J",
        "outputId": "ff62136e-8d27-4ff7-b373-5bf722211920"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  @AppleSupport causing the reply to be disregar...   \n",
            "1  @105835 Your business means a lot to us. Pleas...   \n",
            "2  @76328 I really hope you all change but I'm su...   \n",
            "3  @105836 LiveChat is online at the moment - htt...   \n",
            "4  @VirginTrains see attached error message. I've...   \n",
            "\n",
            "                                             no_html  \n",
            "0  @AppleSupport causing the reply to be disregar...  \n",
            "1  @105835 Your business means a lot to us. Pleas...  \n",
            "2  @76328 I really hope you all change but I'm su...  \n",
            "3  @105836 LiveChat is online at the moment - htt...  \n",
            "4  @VirginTrains see attached error message. I've...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUYOUGNCctI1",
        "outputId": "dff54c8f-8de4-43ed-f13f-8da0cbbc6b48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/608.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "\n",
        "def convert_emojis(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "sample_emoji_text = \"I love NLP üòçüî•\"\n",
        "print(\"Original:\", sample_emoji_text)\n",
        "print(\"Converted:\", convert_emojis(sample_emoji_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImhySkWJc8nf",
        "outputId": "11db13bf-2ef5-4423-b30b-7973d943d924"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: I love NLP üòçüî•\n",
            "Converted: I love NLP :smiling_face_with_heart-eyes::fire:\n"
          ]
        }
      ]
    }
  ]
}